{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DL95x8eVp5c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6812d7f6-0b50-4840-e059-1d280be5d464"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#importing libraries here\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)\n",
        "from pandas import DataFrame\n",
        "from pandas import read_csv\n",
        "from scipy.spatial import distance\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#putting the red wine quality .csv file into a dataframe\n",
        "dataframe = read_csv('/content/drive/My Drive/winequality-white.csv', header = None)\n",
        "dataset = dataframe.values\n",
        "\n",
        "#splits the data into train and test sets, removes the 1st row which are the categories/classifications/etc.\n",
        "x_train, x_test = train_test_split(dataset[1:], test_size = .3, train_size = .7)\n",
        "\n",
        "#normalizes the data\n",
        "norm = preprocessing.Normalizer().fit(x_train)\n",
        "\n",
        "train_normalize = preprocessing.normalize(x_train)\n",
        "train_normalize = norm.fit_transform(train_normalize)\n",
        "test_normalize = preprocessing.normalize(x_test)\n",
        "test_normalize = norm.fit_transform(test_normalize)\n",
        "\n",
        "train_normalize = train_normalize.reshape(train_normalize.shape[1], train_normalize.shape[0])\n",
        "#train_normalize = np.expand_dims(train_normalize, axis = 1)\n",
        "test_normalize = test_normalize.reshape(test_normalize.shape[1], test_normalize.shape[0])\n",
        "#test_normalize = np.expand_dims(test_normalize, axis = 1)\n",
        "\n",
        "#double checking values and other stuff here\n",
        "print(\"train data set shape = \", train_normalize.shape)\n",
        "print(\"test data set shape = \", test_normalize.shape)"
      ],
      "metadata": {
        "id": "ReRx_SAGrTpH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9215ba0-13e5-4970-d47a-139ebb378c59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data set shape =  (12, 3428)\n",
            "test data set shape =  (12, 1470)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#building the sequential model\n",
        "Model_White = tf.keras.models.Sequential(name = \"Model_White\")\n",
        "\n",
        "#layers of the model\n",
        "Model_White.add(tf.keras.layers.Dense(1, input_shape = (3428,))) #input layer\n",
        "Model_White.add(tf.keras.layers.Dense(60, activation = \"relu\"))\n",
        "Model_White.add(tf.keras.layers.Dense(50, activation = \"relu\"))\n",
        "Model_White.add(tf.keras.layers.Dense(40, activation = \"relu\"))\n",
        "Model_White.add(tf.keras.layers.Dense(30, activation = \"relu\"))\n",
        "Model_White.add(tf.keras.layers.Dense(20, activation = \"relu\"))\n",
        "Model_White.add(tf.keras.layers.Dense(10, activation = \"relu\"))\n",
        "Model_White.add(tf.keras.layers.Dense(1470, activation = \"sigmoid\"))#output layer\n",
        "\n",
        "Model_White.compile(optimizer = 'adam', loss = tf.keras.losses.CategoricalCrossentropy(), metrics = ['accuracy'])\n",
        "Model_White.fit(train_normalize, test_normalize, epochs = 200, batch_size = 20, verbose = 1, validation_split = .3)\n",
        "\n",
        "Model_White.summary()\n",
        "history = Model_White.history.history\n",
        "print(\"history loss: \", history.get('loss'))\n",
        "print(\"history val_loss: \", history.get('val_loss'))"
      ],
      "metadata": {
        "id": "eCB-t_BXVlqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.get('loss'), label=\"training loss\")\n",
        "plt.plot(history.get(\"val_loss\"), label=\"validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5KpPjWY0Vpcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#building the modified sequential model\n",
        "Model_White_Modified = tf.keras.models.Sequential(name = \"Model_White_Modified\")\n",
        "\n",
        "#layers of the model\n",
        "Model_White_Modified.add(tf.keras.layers.Dense(1, input_shape = (3428,))) #input layer\n",
        "Model_White_Modified.add(tf.keras.layers.Dropout(0.2))\n",
        "Model_White_Modified.add(tf.keras.layers.Dense(60, activation = \"relu\"))\n",
        "Model_White_Modified.add(tf.keras.layers.Dropout(0.2))\n",
        "Model_White_Modified.add(tf.keras.layers.Dense(50, activation = \"relu\"))\n",
        "Model_White_Modified.add(tf.keras.layers.Dropout(0.2))\n",
        "Model_White_Modified.add(tf.keras.layers.Dense(40, activation = \"relu\"))\n",
        "Model_White_Modified.add(tf.keras.layers.Dropout(0.2))\n",
        "Model_White_Modified.add(tf.keras.layers.Dense(30, activation = \"relu\"))\n",
        "Model_White_Modified.add(tf.keras.layers.Dropout(0.2))\n",
        "Model_White_Modified.add(tf.keras.layers.Dense(20, activation = \"relu\"))\n",
        "Model_White_Modified.add(tf.keras.layers.Dropout(0.2))\n",
        "Model_White_Modified.add(tf.keras.layers.Dense(10, activation = \"relu\"))\n",
        "Model_White_Modified.add(tf.keras.layers.Dropout(0.2))\n",
        "Model_White_Modified.add(tf.keras.layers.Dense(1470, activation = \"sigmoid\"))#output layer\n",
        "\n",
        "Model_White_Modified.compile(optimizer = 'adam', loss = tf.keras.losses.CategoricalCrossentropy(), metrics = ['accuracy'])\n",
        "Model_White_Modified.fit(train_normalize, test_normalize, epochs = 200, batch_size = 20, verbose = 1, validation_split = .3)\n",
        "\n",
        "Model_White_Modified.summary()\n",
        "history = Model_White_Modified.history.history\n",
        "print(\"history loss: \", history.get('loss'))\n",
        "print(\"history val_loss: \", history.get('val_loss'))"
      ],
      "metadata": {
        "id": "UaQNaReM0MUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.get('loss'), label=\"training loss\")\n",
        "plt.plot(history.get(\"val_loss\"), label=\"validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FBV3oboh0Mk7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}