{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZNdGyELoyaV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3c7888e-73f4-44a3-9b61-68d37602695b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#importing libraries here\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)\n",
        "from pandas import DataFrame\n",
        "from pandas import read_csv\n",
        "from scipy.spatial import distance\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#putting the red wine quality .csv file into a dataframe\n",
        "dataframe = read_csv('/content/drive/My Drive/winequality-red.csv', header = None)\n",
        "dataset = dataframe.values\n",
        "\n",
        "#splits the data into train and test sets, removes the 1st row which are the categories/classifications/etc.\n",
        "x_train, x_test = train_test_split(dataset[1:], test_size = .3, train_size = .7)\n",
        "\n",
        "#normalizes the data\n",
        "norm = preprocessing.Normalizer().fit(x_train)\n",
        "\n",
        "train_normalize = preprocessing.normalize(x_train)\n",
        "train_normalize = norm.fit_transform(train_normalize)\n",
        "test_normalize = preprocessing.normalize(x_test)\n",
        "test_normalize = norm.fit_transform(test_normalize)\n",
        "\n",
        "train_normalize = train_normalize.reshape(train_normalize.shape[1], train_normalize.shape[0])\n",
        "#train_normalize = np.expand_dims(train_normalize, axis = 1)\n",
        "test_normalize = test_normalize.reshape(test_normalize.shape[1], test_normalize.shape[0])\n",
        "#test_normalize = np.expand_dims(test_normalize, axis = 1)\n",
        "\n",
        "#double checking values and other stuff here\n",
        "print(\"train data set shape = \", train_normalize.shape)\n",
        "print(\"test data set shape = \", test_normalize.shape)"
      ],
      "metadata": {
        "id": "FRQg3A7WrS9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#building the sequential model\n",
        "Model_Red = tf.keras.models.Sequential(name = \"Model_Red\")\n",
        "\n",
        "#layers of the model\n",
        "Model_Red.add(tf.keras.layers.Dense(1, input_shape = (1119,))) #input layer\n",
        "Model_Red.add(tf.keras.layers.Dense(60, activation = \"relu\"))\n",
        "Model_Red.add(tf.keras.layers.Dense(50, activation = \"relu\"))\n",
        "Model_Red.add(tf.keras.layers.Dense(40, activation = \"relu\"))\n",
        "Model_Red.add(tf.keras.layers.Dense(30, activation = \"relu\"))\n",
        "Model_Red.add(tf.keras.layers.Dense(20, activation = \"relu\"))\n",
        "Model_Red.add(tf.keras.layers.Dense(10, activation = \"relu\"))\n",
        "Model_Red.add(tf.keras.layers.Dense(480, activation = \"sigmoid\"))#output layer\n",
        "\n",
        "Model_Red.compile(optimizer = 'adam', loss = tf.keras.losses.CategoricalCrossentropy(), metrics = ['accuracy'])\n",
        "Model_Red.fit(train_normalize, test_normalize, epochs = 200, batch_size = 20, verbose = 1, validation_split = .3)\n",
        "\n",
        "Model_Red.summary()\n",
        "history = Model_Red.history.history\n",
        "print(\"history loss: \", history.get('loss'))\n",
        "print(\"history val_loss: \", history.get('val_loss'))"
      ],
      "metadata": {
        "id": "ySvxdlp07xFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.get('loss'), label=\"training loss\")\n",
        "plt.plot(history.get(\"val_loss\"), label=\"validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UuQWPoZga0KY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#building the modified sequential model\n",
        "Model_Red_Modified = tf.keras.models.Sequential(name = \"Model_Red_Modified\")\n",
        "\n",
        "#layers of the model w/ dropout layers between the hidden layers\n",
        "Model_Red_Modified.add(tf.keras.layers.Dense(1, input_shape = (1119,))) #input layer\n",
        "Model_Red_Modified.add(tf.keras.layers.Dropout(0.2))\n",
        "Model_Red_Modified.add(tf.keras.layers.Dense(60, activation = \"relu\"))\n",
        "Model_Red_Modified.add(tf.keras.layers.Dropout(0.2))\n",
        "Model_Red_Modified.add(tf.keras.layers.Dense(50, activation = \"relu\"))\n",
        "Model_Red_Modified.add(tf.keras.layers.Dropout(0.2))\n",
        "Model_Red_Modified.add(tf.keras.layers.Dense(40, activation = \"relu\"))\n",
        "Model_Red_Modified.add(tf.keras.layers.Dropout(0.2))\n",
        "Model_Red_Modified.add(tf.keras.layers.Dense(30, activation = \"relu\"))\n",
        "Model_Red_Modified.add(tf.keras.layers.Dropout(0.2))\n",
        "Model_Red_Modified.add(tf.keras.layers.Dense(20, activation = \"relu\"))\n",
        "Model_Red_Modified.add(tf.keras.layers.Dropout(0.2))\n",
        "Model_Red_Modified.add(tf.keras.layers.Dense(10, activation = \"relu\"))\n",
        "Model_Red_Modified.add(tf.keras.layers.Dropout(0.2))\n",
        "Model_Red_Modified.add(tf.keras.layers.Dense(480, activation = \"sigmoid\"))#output layer\n",
        "\n",
        "Model_Red_Modified.compile(optimizer = 'adam', loss = tf.keras.losses.CategoricalCrossentropy(), metrics = ['accuracy'])\n",
        "Model_Red_Modified.fit(train_normalize, test_normalize, epochs = 200, batch_size = 20, verbose = 1, validation_split = .3)\n",
        "\n",
        "Model_Red_Modified.summary()\n",
        "history = Model_Red_Modified.history.history\n",
        "print(\"history loss: \", history.get('loss'))\n",
        "print(\"history val_loss: \", history.get('val_loss'))"
      ],
      "metadata": {
        "id": "-w1EWo_9FsR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.get('loss'), label=\"training loss\")\n",
        "plt.plot(history.get(\"val_loss\"), label=\"validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZzT6I2G8xe7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "jupyter nbconvert --to html Wine_21_White.ipynb"
      ],
      "metadata": {
        "id": "8LBmd20u4V1z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}